description: "e007 larger model"
num_epochs: 7
train_folds: [0, 1, 2, 3, 4]
accum_mod: 8
trn_batch_size: 4
val_batch_size: 16
tst_batch_size: 16
booster_trn_data:
  - data/dataset/mlqa-hindi-processed/mlqa_hindi.csv
  - data/dataset/mlqa-hindi-processed/xquad.csv
preprocessor:
    preprocessor_type: baseline_kernel_v1
    tokenizer_type: data/dataset/deepset/xlm-roberta-large-squad2/
model:
    model_type: chaii-qa-xlmrb-1
    pretrained_model_name_or_path: data/dataset/deepset/xlm-roberta-large-squad2/
