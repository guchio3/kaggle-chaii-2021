description: "e022 text batch linear warmup"
num_epochs: 3
train_folds: [0, 1, 2, 3, 4]
accum_mod: 8
trn_batch_size: 4
val_batch_size: 16
tst_batch_size: 16
booster_trn_data:
  - data/dataset/mlqa-hindi-processed/mlqa_hindi.csv
  - data/dataset/mlqa-hindi-processed/xquad.csv
preprocessor:
    preprocessor_type: baseline_kernel_v1
    tokenizer_type: data/dataset/deepset/xlm-roberta-large-squad2/
    max_length: 400
    stride: 135
model:
    model_type: chaii-text-batch-xlmrb-1
    pretrained_model_name_or_path: data/dataset/deepset/xlm-roberta-large-squad2/
    max_grad_norm: 1.0
    start_loss_weight: 1.0
    end_loss_weight: 1.0
    segmentation_loss_weight: 1.0
optimizer:
    learning_rate: 0.00001
fobj: 
    fobj_type: bce
scheduler:
    scheduler_type: linear_warmup
    warmup_ratio: 0.1
